{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fed CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGpTrip1L240yGVM+z/oUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "136d344d07a74453ac13ff72321bab0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca678b4fd614405eadc2f4cac49e0aaa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab8e5d673e714c40bfed987ccf2ffbd6",
              "IPY_MODEL_f6731bc49a4746798b7787bae15cfb14"
            ]
          }
        },
        "ca678b4fd614405eadc2f4cac49e0aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab8e5d673e714c40bfed987ccf2ffbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d62debfd7f94360b0af1490c5b7f0e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95e8ed0591004710bb9edac53f35e9e6"
          }
        },
        "f6731bc49a4746798b7787bae15cfb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a103722a97aa4545b7df890f238b9793",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [1:21:33&lt;00:00, 34844.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d77a7cbc03743619d9dda7fc65f688d"
          }
        },
        "5d62debfd7f94360b0af1490c5b7f0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95e8ed0591004710bb9edac53f35e9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a103722a97aa4545b7df890f238b9793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d77a7cbc03743619d9dda7fc65f688d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaolotelli/FedLearn/blob/main/Fed_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhw68bg7z_FU"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30oaEgEVz1Wu"
      },
      "source": [
        "import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBlqGxpSj09"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, BatchSampler, RandomSampler\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSXsYnkqz5gm"
      },
      "source": [
        "download CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "136d344d07a74453ac13ff72321bab0e",
            "ca678b4fd614405eadc2f4cac49e0aaa",
            "ab8e5d673e714c40bfed987ccf2ffbd6",
            "f6731bc49a4746798b7787bae15cfb14",
            "5d62debfd7f94360b0af1490c5b7f0e4",
            "95e8ed0591004710bb9edac53f35e9e6",
            "a103722a97aa4545b7df890f238b9793",
            "0d77a7cbc03743619d9dda7fc65f688d"
          ]
        },
        "id": "g6g3B3hnTNvJ",
        "outputId": "c60c8811-dfc1-49a4-faca-6c00f1e59783"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                download=True, transform=transform)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "136d344d07a74453ac13ff72321bab0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBBK5frT0Gq3"
      },
      "source": [
        "generate non-iid clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVw7owDDlUnh"
      },
      "source": [
        "# generate non-iid clients from Dirichlet prior distribution\n",
        "# the idea of this part comes from https://github.com/IBM/probabilistic-federated-neural-matching\n",
        "K = 10\n",
        "alpha = 0.5\n",
        "num_clients = 100\n",
        "min_size = 0\n",
        "y_train = np.array(trainset.targets)\n",
        "\n",
        "while min_size < 10:\n",
        "  client_idxs = [[] for _ in range(num_clients)]\n",
        "  for k in range(K):\n",
        "    ps = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
        "    idx_k = np.where(y_train == k)[0]\n",
        "    np.random.shuffle(idx_k)\n",
        "    ps = (np.cumsum(ps)*len(idx_k)).astype(int)[:-1]\n",
        "    client_idx_k = np.split(idx_k, ps)\n",
        "    client_idxs = [client_idx + idx.tolist() for client_idx, idx in zip(client_idxs, client_idx_k)]\n",
        "    min_size = min([len(client_idx) for client_idx in client_idxs])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtrp3Dz0KFl"
      },
      "source": [
        "define client data object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY_9HkJEUOos"
      },
      "source": [
        "class Client_Data(object):\n",
        "  def __init__(self, dataset, id):\n",
        "    idx = client_idxs[id]\n",
        "    self.X = dataset.data[idx]\n",
        "    self.y = np.array(dataset.targets)[idx]\n",
        "\n",
        "  # must define len() method for Client Data object\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.X[i], self.y[i]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz04WMMLFb-l"
      },
      "source": [
        "define custom Dataset object for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv2VSSZABuD6"
      },
      "source": [
        "class Client_Dataset(Dataset):\n",
        "  def __init__(self, X, y, transform = transform):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.transform = transform\n",
        "\n",
        "  # custom Dataset object must define __len__ and __getitem__ methods\n",
        "  # len method\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  # getitem method\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.fromarray(self.X[idx])\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img, torch.tensor(self.y[idx])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GqZqWPHaCs5"
      },
      "source": [
        "## Define client and server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM74TCqZaFXc"
      },
      "source": [
        "class Client(object):\n",
        "  \"\"\"Client for local training\n",
        "\n",
        "  Args:\n",
        "    id: id for identify clients\n",
        "    client_data (:obj:'Client_Data'): data stored in client\n",
        "\n",
        "  Attributes:\n",
        "    id: id for identify clients\n",
        "    client_data: data stored in client\n",
        "  \"\"\"\n",
        "  def __init__(self, id, client_data):\n",
        "    self.id = id\n",
        "    self.client_data = client_data\n",
        "\n",
        "  def create_model(self, Learner, initial_params, learning_rate):\n",
        "    \"\"\"generate local model\n",
        "\n",
        "    Args:\n",
        "      Learner (:obj:'nn.Module'): learning model\n",
        "      initial_params (:obj:'list' of :obj:'np.array): a list contains shape(-1) arrays of parameters of model\n",
        "      learning_rate: learning rate\n",
        "    \"\"\"\n",
        "    self.model = Learner(initial_params, learning_rate)\n",
        "\n",
        "  def update_model(self, params):\n",
        "    \"\"\"assign new params to local model\n",
        "\n",
        "    Args:\n",
        "      params (:obj:'list' of :obj:'np.array): a list contains shape(-1) arrays of parameters\n",
        "    \"\"\"\n",
        "    self.model.assign_params(params)\n",
        "\n",
        "  def train(self, epoch, batch_size):\n",
        "    \"\"\"local training\n",
        "\n",
        "    Args:\n",
        "      epoch: epochs for local training\n",
        "      batch_size: batch size for local training\n",
        "\n",
        "    Returns:\n",
        "      num_example: number of data contained in this client\n",
        "      loss: training loss\n",
        "    \"\"\"\n",
        "    self.model.gd(self.client_data, epoch, batch_size)\n",
        "    loss = self.model.solve_loss(self.client_data)\n",
        "    num_example = len(self.client_data)\n",
        "    return num_example, loss\n",
        "\n",
        "  def sgd(self, batch_size):\n",
        "    \"\"\"apply gradient descent randomly on a mini-batch\n",
        "\n",
        "    Args:\n",
        "      batch_size: batch size for mini-batch\n",
        "\n",
        "    Returns:\n",
        "      num_example: number of data contained in this client\n",
        "      loss: training loss of model\n",
        "      grads: gradients of model on mini-batch data\n",
        "    \"\"\"\n",
        "    loss, grads = self.model.sgd(self.client_data, batch_size)\n",
        "    num_example = len(self.client_data)\n",
        "    return num_example, loss, grads"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP2HH1Q-aHaB"
      },
      "source": [
        "class Server(object):\n",
        "  \"\"\"Server for training control\n",
        "\n",
        "  Args:\n",
        "    ids (list): list of client id numbers\n",
        "    Learner: name of model object\n",
        "    initial_params (:obj:'list' of :obj:'np.array): a list contains shape(-1) arrays of parameters of model\n",
        "    learning_rate: learning rate for local model\n",
        "\n",
        "  Attributes:\n",
        "    ids: list of client id numbers\n",
        "    learner: model name\n",
        "    model: server model\n",
        "  \"\"\"\n",
        "  def __init__(self, train_data, ids, Learner, initial_params, learning_rate):\n",
        "    self.ids = ids\n",
        "    self.learner = Learner\n",
        "    self.clients = self.set_clients(train_data)\n",
        "    self.model = self.learner(initial_params, learning_rate)\n",
        "\n",
        "  def set_clients(self, train_data):\n",
        "    \"\"\"set clients with training data\n",
        "    \"\"\"\n",
        "    clients = []\n",
        "    for id in self.ids:\n",
        "      client_data = Client_Data(train_data, id)\n",
        "      c = Client(id, client_data)\n",
        "      c.create_model(self.learner, initial_params, learning_rate)\n",
        "      clients.append(c)\n",
        "    return clients\n",
        "\n",
        "  def send_model(self):\n",
        "    \"\"\"send newest model to all clients\n",
        "    \"\"\"\n",
        "    params = self.model.print_params()\n",
        "    for c in self.clients:\n",
        "      c.update_model(params)\n",
        "\n",
        "  def select_client(self, select_rate):\n",
        "    \"\"\"select clients for each iteration\n",
        "    \"\"\"\n",
        "    self.num_clients = np.maximum(1, np.int(np.floor(len(self.ids) * select_rate)))\n",
        "    select_ids = np.random.choice(self.ids, self.num_clients, replace=False)\n",
        "    select_clients = []\n",
        "    for id in select_ids:\n",
        "      loc_id = np.array([id == idx for idx in self.ids])\n",
        "      ind = np.int(np.array(range(len(self.ids)))[loc_id])\n",
        "      select_client = self.clients[ind]\n",
        "      select_clients.append(select_client)\n",
        "    return select_clients"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41WeataIaT2A"
      },
      "source": [
        "## define training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX0T05BLaULk"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiFwzx6uaX4S",
        "outputId": "2fc0ab8c-b3bb-4bbf-86e7-97a6199647f1"
      },
      "source": [
        "# check if device is gpu or not\n",
        "dev = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "dev"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rim9xQtXaYW7"
      },
      "source": [
        "class cifar10_CNN(nn.Module):\n",
        "  def __init__(self, initial_params, learning_rate):\n",
        "    \"\"\" CNN model for CIFAR10 dataset\n",
        "    the CNN model structure is from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "    Args:\n",
        "      initial_params (:obj:'list' of :obj:'np.array): a list contains shape(-1) arrays of parameters of model. \n",
        "        if initial_params is None, it will generate random initial parameters. \n",
        "      learning_rate: learning rate\n",
        "\n",
        "    Attributes:\n",
        "      loss_func: loss function\n",
        "      lr: learning rate\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.lr = learning_rate\n",
        "    self.loss_func = F.cross_entropy\n",
        "    if initial_params is not None:\n",
        "      self.assign_params(initial_params)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.pool(F.relu(self.conv1(xb)))\n",
        "    xb = self.pool(F.relu(self.conv2(xb)))\n",
        "    xb = xb.view(-1, 16 * 5 * 5)\n",
        "    xb = F.relu(self.fc1(xb))\n",
        "    xb = F.relu(self.fc2(xb))\n",
        "    xb = self.fc3(xb)\n",
        "    return xb\n",
        "\n",
        "  def gd(self, client_data, epoch, batch_size):\n",
        "    \"\"\"gradient descent on client data\n",
        "\n",
        "    Args:\n",
        "      client_data (:obj:'Client_Data'): data to train model on\n",
        "      epoch: epochs for training\n",
        "      batch_size: batch size for training\n",
        "    \"\"\"\n",
        "    #X, y = map(torch.tensor, (client_data.X, client_data.y))\n",
        "    X, y = client_data.X, client_data.y\n",
        "    \n",
        "    if dev == torch.device(\"cuda\"):\n",
        "      # training with GPU\n",
        "      self.to(dev)\n",
        "\n",
        "    train_ds = Client_Dataset(X, y)\n",
        "    train_dl = DataLoader(train_ds, batch_size = batch_size)\n",
        "    opt = optim.SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
        "    \n",
        "    for _ in range(epoch):\n",
        "      for xb, yb in train_dl:\n",
        "        if dev == torch.device(\"cuda\"):\n",
        "          # training with GPU\n",
        "          xb, yb = xb.to(dev), yb.to(dev)\n",
        "        pred = self.forward(xb)\n",
        "        loss = self.loss_func(pred, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "  def sgd(self, client_data, batch_size):\n",
        "    \"\"\"stochastic gradient descent\n",
        "\n",
        "    Args:\n",
        "      client_data (:obj:'Client_Data'): data to train model on\n",
        "      batch_size: batch size for training\n",
        "\n",
        "    Returns:\n",
        "      loss_value: loss value\n",
        "      grads (:obj:'list' of :obj:'np.array'): stochastic gradients on mini-batch data\n",
        "    \"\"\"\n",
        "    #X, y = map(torch.tensor, (client_data.X, client_data.y))\n",
        "    X, y = client_data.X, client_data.y\n",
        "    \n",
        "    if dev == torch.device(\"cuda\"):\n",
        "      # training with GPU\n",
        "      self.to(dev)\n",
        "\n",
        "    train_ds = Client_Dataset(X, y)\n",
        "    train_dl = DataLoader(train_ds, \n",
        "        sampler = BatchSampler(RandomSampler(train_ds), \n",
        "        batch_size = batch_size, drop_last = False\n",
        "    ))\n",
        "    opt = optim.SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
        "    \n",
        "    xb, yb = next(iter(train_dl))\n",
        "    yb = yb.view(-1)\n",
        "    if dev == torch.device(\"cuda\"):\n",
        "      # training with GPU\n",
        "      xb, yb = xb.to(dev), yb.to(dev)\n",
        "    pred = self.forward(xb)\n",
        "    loss = self.loss_func(pred, yb)\n",
        "    loss.backward()\n",
        "    \n",
        "    if dev == torch.device(\"cuda\"):\n",
        "      grads = [p.grad.view(-1).cpu().detach().numpy() for p in self.parameters()]\n",
        "    else:\n",
        "      grads = [p.grad.view(-1).detach().numpy() for p in self.parameters()]\n",
        "    loss_value = self.solve_loss(client_data)\n",
        "\n",
        "    return loss_value, grads\n",
        "\n",
        "  def assign_params(self, params):\n",
        "    self.conv1.weight = nn.Parameter(torch.tensor(params[0].reshape(6, 3, 5, 5), dtype=torch.float32))\n",
        "    self.conv1.bias = nn.Parameter(torch.tensor(params[1], dtype=torch.float32))\n",
        "    self.conv2.weight = nn.Parameter(torch.tensor(params[2].reshape(16, 6, 5, 5), dtype=torch.float32))\n",
        "    self.conv2.bias = nn.Parameter(torch.tensor(params[3], dtype=torch.float32))\n",
        "    self.fc1.weight = nn.Parameter(torch.tensor(params[4].reshape(120, 400), dtype=torch.float32))\n",
        "    self.fc1.bias = nn.Parameter(torch.tensor(params[5], dtype=torch.float32))\n",
        "    self.fc2.weight = nn.Parameter(torch.tensor(params[6].reshape(84, 120), dtype=torch.float32))\n",
        "    self.fc2.bias = nn.Parameter(torch.tensor(params[7], dtype=torch.float32))\n",
        "    self.fc3.weight = nn.Parameter(torch.tensor(params[8].reshape(10, 84), dtype=torch.float32))\n",
        "    self.fc3.bias = nn.Parameter(torch.tensor(params[9], dtype=torch.float32))\n",
        "\n",
        "  def print_params(self):\n",
        "    \"\"\"print model parameters\n",
        "\n",
        "    Returns:\n",
        "      model parameters\n",
        "    \"\"\"\n",
        "    if dev == torch.device(\"cuda\"):\n",
        "      params = [p.cpu().detach().numpy().reshape(-1) for p in self.parameters()]\n",
        "    else:\n",
        "      params = [p.detach().numpy().reshape(-1) for p in self.parameters()]\n",
        "    return params\n",
        "  \n",
        "  def solve_loss(self, client_data):\n",
        "    \"\"\"return the loss value on given data\n",
        "\n",
        "    Args:\n",
        "      client_data (:obj:'Client_Data'): data to compute loss value on\n",
        "\n",
        "    Returns:\n",
        "      loss value on given data\n",
        "    \"\"\"\n",
        "    X, y = client_data.X, client_data.y\n",
        "    train_ds = Client_Dataset(X, y)\n",
        "    train_dl = DataLoader(train_ds, batch_size = 1)\n",
        "\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for xb, yb in train_dl:\n",
        "        if dev == torch.device(\"cuda\"):\n",
        "          xb, yb = xb.to(dev), yb.to(dev)\n",
        "        pred = self.forward(xb)\n",
        "        loss = self.loss_func(pred, yb)\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    return total_loss\n",
        "\n",
        "  def predict_accu(self, client_data):\n",
        "    \"\"\"return the loss value on given data\n",
        "\n",
        "    Args:\n",
        "      client_data (:obj:'Client_Data'): data to compute loss value on\n",
        "\n",
        "    Returns:\n",
        "      predict accuracy on given data\n",
        "    \"\"\"\n",
        "    X, y = client_data.X, client_data.y\n",
        "    train_ds = Client_Dataset(X, y)\n",
        "    train_dl = DataLoader(train_ds, batch_size = 10)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for xb, yb in train_dl:\n",
        "        if dev == torch.device(\"cuda\"):\n",
        "          xb, yb = xb.to(dev), yb.to(dev)\n",
        "        pred = self.forward(xb)\n",
        "        y_pred = F.softmax(pred, dim = 1).detach().argmax(axis = 1)\n",
        "        total += yb.size(0)\n",
        "        correct += (y_pred == yb).sum().item()\n",
        "\n",
        "    return correct / total"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBZIGpXjkRBp"
      },
      "source": [
        "## Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTpG9cgskTIc"
      },
      "source": [
        "FedAvg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPBytYEukOJz"
      },
      "source": [
        "class WAVGM(Server):\n",
        "  \"\"\"child class of Server to define certain aggregation method\n",
        "  WAVGM denotes weighted average model which is the same as FedAvg\n",
        "  \"\"\"\n",
        "  def __init__(self, train_data, ids, Learner, initial_params, learning_rate):\n",
        "    super(WAVGM, self).__init__(train_data, ids, Learner, initial_params, learning_rate)\n",
        "\n",
        "  def train(self, epoch, batch_size, select_rate=1):\n",
        "    \"\"\"apply one iteration of local training\n",
        "\n",
        "    Args:\n",
        "      epoch: local training epochs\n",
        "      batch_size: local training batch size\n",
        "      select_rate: the rate of clients to be trained per iteration\n",
        "\n",
        "    Returns:\n",
        "      sum of local losses\n",
        "    \"\"\"\n",
        "    self.send_model()\n",
        "    self.select_clients = self.select_client(select_rate)\n",
        "    losses = []\n",
        "    self.client_nums = []\n",
        "    for client in self.select_clients:\n",
        "      client_num, client_loss = client.train(epoch, batch_size)\n",
        "      losses.append(client_loss)\n",
        "      self.client_nums.append(client_num)\n",
        "      # print('Client: {}, Local_loss: {:f}'.format(client.id, client_loss))\n",
        "    self.aggregate()\n",
        "    return np.sum(losses)\n",
        "  \n",
        "  def aggregate(self):\n",
        "    \"\"\"custom aggregation method\n",
        "    simple average for FedAvg in this case\n",
        "\n",
        "    Returns:\n",
        "      averaged parameters\n",
        "    \"\"\"\n",
        "    total_params = [np.zeros(len(param)) for param in self.model.print_params()]\n",
        "    total_num = sum(self.client_nums)\n",
        "    t = 0\n",
        "    for c in self.select_clients:\n",
        "      for i in range(len(total_params)):\n",
        "        total_params[i] = total_params[i] + self.client_nums[t] / total_num * c.model.print_params()[i]\n",
        "      t += 1\n",
        "    self.model.assign_params(total_params)\n",
        "    return total_params"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75x6glsFAvjs"
      },
      "source": [
        "## Save and load pre-trained parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t87DZpHrA9GO",
        "outputId": "495ad1af-52fc-4029-895a-98e995a9d142"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwGu6xO_BEOc",
        "outputId": "2899cf8f-bb08-4e46-91b8-70729eedc6b2"
      },
      "source": [
        "!ls \"/content/gdrive/MyDrive\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AFL_EMNIST_model_saving_file0\t CIFAR10_model_saving_file6\n",
            " AFL_EMNIST_model_saving_file1\t CIFAR10_model_saving_file7\n",
            " AFL_EMNIST_model_saving_file2\t CIFAR10_model_saving_file8\n",
            " AFL_EMNIST_model_saving_file3\t CIFAR10_model_saving_file9\n",
            " AFL_EMNIST_model_saving_file4\t'Colab Notebooks'\n",
            " AFL_EMNIST_model_saving_file5\t EMNIST_model_saving_file0\n",
            " AFL_EMNIST_model_saving_file6\t EMNIST_model_saving_file1\n",
            " CIFAR10_model_saving_file0\t EMNIST_model_saving_file2\n",
            " CIFAR10_model_saving_file1\t EMNIST_model_saving_file3\n",
            " CIFAR10_model_saving_file2\t EMNIST_model_saving_file4\n",
            " CIFAR10_model_saving_file3\t EMNIST_model_saving_file5\n",
            " CIFAR10_model_saving_file4\t'Getting started.pdf'\n",
            " CIFAR10_model_saving_file5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9VZvBuyBKJe"
      },
      "source": [
        "load parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbe9KJfiBGu-"
      },
      "source": [
        "read_params = [np.fromfile('/content/gdrive/My Drive/CIFAR10_model_saving_file'+str(i), dtype = np.float32) for i in range(10)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX_ScVpWkjem"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7oaKEpekloU"
      },
      "source": [
        "IDs = np.arange(num_clients)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfA2Y5-RBa8I"
      },
      "source": [
        "training with random initial params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lturq1vCkuqw"
      },
      "source": [
        "initial_params = None\n",
        "learning_rate = 0.001\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NGeO-ytBYgX"
      },
      "source": [
        "training with pre-trained params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG7XZ4psBYGs"
      },
      "source": [
        "initial_params = read_params\n",
        "learning_rate = 0.001\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 10"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfi0ZmpUk6_w"
      },
      "source": [
        "FedAvg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHWJKr6yk7T4"
      },
      "source": [
        "CNN_AVGM_fit = WAVGM(trainset, IDs, cifar10_CNN, initial_params, learning_rate)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0jsQuzsk-se"
      },
      "source": [
        "ITER = 20\n",
        "for i in range(ITER):\n",
        "  loss = CNN_AVGM_fit.train(EPOCH, BATCH_SIZE)\n",
        "  print('----------iter: {:d}/{:d}, loss: {:f}----------'.format(i+1, ITER, loss))\n",
        "  if (i+1) % 5 == 0:\n",
        "    final_model = CNN_AVGM_fit.model\n",
        "    for k, param in enumerate(final_model.print_params()):\n",
        "      param.tofile('/content/gdrive/My Drive/CIFAR10_model_saving_file'+str(k))\n",
        "    print('iter {:d}: model parameters have been saved'.format(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGfqFC9q9DHS"
      },
      "source": [
        "final_model = CNN_AVGM_fit.model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTyggjQj4cSN"
      },
      "source": [
        "sample_data = Client_Data(trainset, 0)\n",
        "sample_data.X = testset.data\n",
        "sample_data.y = testset.targets"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doAlmw_Unw2O",
        "outputId": "fcad6b65-eced-444e-8b1c-8e07dbc6724b"
      },
      "source": [
        "final_model.to(dev)\n",
        "final_model.predict_accu(sample_data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}